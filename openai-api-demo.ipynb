{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e291b18d-a1f0-4068-9290-c9b937567e3e",
   "metadata": {},
   "source": [
    "# Cracking Open the OpenAI API\n",
    "\n",
    "Code authored by: Shawhin Talebi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25acaea-c334-4254-8635-64270dc6c397",
   "metadata": {},
   "source": [
    "### set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edd17a3-6cde-4cdf-8f29-c9e1e533d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b30b225-6b7c-48ca-8c13-05a75146d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your security key\n",
    "openai.api_key = \"bcoeiwugiBiuGDIUbfiabifIUIBUIB\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75b3c4-cce9-4d82-888c-078a4e9ae1fa",
   "metadata": {},
   "source": [
    "### code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100350ea-c690-49d3-84cc-84b192c18500",
   "metadata": {},
   "source": [
    "##### First call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb7a1c4f-b4dc-453f-8e63-bc016f2de35e",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create a chat completion\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m chat_completion \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mListen to your\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.conda\\envs\\myenv\\lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                               messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6288eb8-03d7-45f5-9e40-3912afe2a39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-7dk1Jkf5SDm2422nYRPL9x0QrlhI4',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1689706049,\n",
       " 'model': 'gpt-3.5-turbo-0613',\n",
       " 'choices': [<OpenAIObject at 0x7f9d1a862b80> JSON: {\n",
       "    \"index\": 0,\n",
       "    \"message\": {\n",
       "      \"role\": \"assistant\",\n",
       "      \"content\": \"heart.\"\n",
       "    },\n",
       "    \"finish_reason\": \"stop\"\n",
       "  }],\n",
       " 'usage': <OpenAIObject at 0x7f9d1a862c70> JSON: {\n",
       "   \"prompt_tokens\": 10,\n",
       "   \"completion_tokens\": 2,\n",
       "   \"total_tokens\": 12\n",
       " }}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340f7ccf-c599-443c-89d8-e509039d673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart.\n"
     ]
    }
   ],
   "source": [
    "# print the chat completion\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e3b38-0bb2-48de-9d3f-ee5013f4a689",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### max tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf02f54e-004e-409b-942d-74a4d855c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                               messages=[\n",
    "                                                   {\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                               max_tokens=1)\n",
    "\n",
    "# print the chat completion\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f966f-7370-46d3-ae12-c955565b9617",
   "metadata": {},
   "source": [
    "##### n = number of chat completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad49735c-88c2-4563-a1c6-0020a8905e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart.\n",
      "heart and\n",
      "heart.\n",
      "\n",
      "heart,\n",
      "\n",
      "heart,\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                               messages=[\n",
    "                                                   {\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                               max_tokens=2,\n",
    "                                               n=5)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ffa97-eb11-4ca9-a8d4-29502ee0cdc6",
   "metadata": {},
   "source": [
    "##### temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638b828b-b323-4cd8-90ea-5106146635a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart.\n",
      "heart.\n",
      "heart.\n",
      "heart.\n",
      "heart.\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                               messages=[\n",
    "                                                   {\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                               max_tokens=2,\n",
    "                                               n=5,\n",
    "                                               temperature=0)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78dd7ad-5790-441f-981d-60de6c61104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judgment\n",
      "Advice\n",
      ".inner awareness\n",
      "heart.\n",
      "\n",
      "ging ist\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                               messages=[\n",
    "                                                   {\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                               max_tokens=2,\n",
    "                                               n=5,\n",
    "                                               temperature=2)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc228536-a0b6-4a7f-81f7-382c3205ee8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Demo: Lyric Completion Assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ece8e6a6-ebe0-4ff1-b132-e8bc8759e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial prompt with system message and 2 task examples\n",
    "messages_list = [{\"role\": \"system\", \"content\": \"I am Roxette lyric completion assistant. When given a line from a song, I will provide the next line in the song.\"},\n",
    "                 {\"role\": \"user\", \"content\": \"I know there's something in the wake of your smile\"},\n",
    "                 {\"role\": \"assistant\",\n",
    "                     \"content\": \"I get a notion from the look in your eyes, yeah\"},\n",
    "                 {\"role\": \"user\", \"content\": \"You've built a love but that love falls apart\"},\n",
    "                 {\"role\": \"assistant\",\n",
    "                     \"content\": \"Your little piece of Heaven turns too dark\"},\n",
    "                 {\"role\": \"user\", \"content\": \"Listen to your\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b51fdc0-7f91-4524-a27e-739a9fb3f795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart when he's calling for you\n",
      "Listen to your heart, there's nothing else you can do\n",
      "I don't know where you're going and I don't know why\n",
      "But listen to your heart before you tell him goodbye\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    # create a chat completion\n",
    "    chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                                   messages=messages_list,\n",
    "                                                   max_tokens=15,\n",
    "                                                   n=1,\n",
    "                                                   temperature=0)\n",
    "\n",
    "    # print the chat completion\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "\n",
    "    # append new message to message list\n",
    "    new_message = {\"role\": \"assistant\",\n",
    "                   \"content\": chat_completion.choices[0].message.content}\n",
    "    messages_list.append(new_message)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2168d7-8842-47d0-a7cc-02c5ea505a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual lyrics:\n",
    "\n",
    "# Listen to your heart when he's calling for you\n",
    "# Listen to your heart, there's nothing else you can do\n",
    "# I don't know where you're going and I don't know why\n",
    "# But listen to your heart before you tell him goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588989b-dc89-4c3b-898e-05aec70a8426",
   "metadata": {},
   "source": [
    "##### Crank the temp! (warning: it gets weird)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fc19d9a-b1e3-49bd-9c20-f370da0e6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I reach into the shadows summon Sweet Elaine\n",
      "﻿Pointing all steel values fails if friends remote empty Reply\n",
      "\n",
      "Image existing\n",
      "Long seconds confirm flesh pressed secretly Remember saint talk dying To unfamiliar pieces Father blessed\n",
      "Speech keeps passing shape raises You travel feeling shadows Thriven bodies swept Spirit consume\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    # create a chat completion\n",
    "    chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                                   messages=messages_list,\n",
    "                                                   max_tokens=15,\n",
    "                                                   n=1,\n",
    "                                                   temperature=2)\n",
    "\n",
    "    # print the chat completion\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "\n",
    "    new_message = {\"role\": \"assistant\",\n",
    "                   \"content\": chat_completion.choices[0].message.content}\n",
    "    messages_list.append(new_message)\n",
    "    time.sleep(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
